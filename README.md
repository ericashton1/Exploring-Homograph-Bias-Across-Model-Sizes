# NLP-Final-Project-Exploring-Homograph-Bias-Across-Model-Sizes

## Overview 

Homographs are words that are spelled the same with categorically different meanings. In this paper, we investigate if BERT and RoBERTa treat homographs differently from their non-homograph synonyms in a minimal pair experiment. Specifically, we look at frequency-adjusted surprisal to see if homographs tend to be more or less surprising than non-homographs and if this varies across model sizes. Both models showed significantly lower surprisal for homographs over their non-homograph synonyms, though this bias was smaller in RoBERTa, the model with a larger training size. These results suggest that as training size increases, models become more familiar with the more subtle contextual variance of non-homographs and thus exhibit a narrower surprisal difference between homographs and non-homographs. Thus, our study implies that models require less training to adequately learn the various contexts of a homograph than to adequately learn the more subtle varying contexts of a non-homograph.


## Going from dataset to tsv format

First, we will create a list of 50 homonyms and 5 synonyms for each definition. We will then download the [open subtitles dataset](https://huggingface.co/datasets/sentence-transformers/parallel-sentences-opensubtitles) from HuggingFace. Once we have loaded the dataset into python, we can iterate through all the English subtitles, checking each word to see if it is in a set of all the synonyms. If it is, we will add it to our dataset with the ROI (index at which the word was found) and add 1 to a counter which we can use as textid. We will repeat this process until we have 30,000 sentences. Once we have these 30,000 sentences, we can use a dictionary lookup to find another synonym that will replace the word in its pair and the appropriate homonym which will replace the word in its other pair. Then we can format these into a pd dataframe and then a tsv.


## Going from output of NLPScholar to evaluation metrics, tables, and figures

The evaluation of our NLPScholar experiment will give us probability of the original word in the sentence (word a), a non-homonym synonym (word b), and a homonym synonym (word c). We are concerned with the difference between word a and word b compared to the difference between word a and word c. Thus we can iterate through, gathering average difference as well as number of instances where the probability disparity between word a and b is less than the probability disparity between word a and word c (evidence of bias against homonyms). This will then allow us to chart difference between each set of two pairs and give us a percentage of pairs where non-homonyms were favored for each model. We can also create a chart with points plotted for difference between each set of two pairs color-coded by model to potentially show how training size affects homonym bias.

Additionally, if we have time and are still interested in embeddings, we can use the output from NLPScholar to potentially show correlation to similarity between static and contextual embeddings. That is, we can plot each pair on a chart where one axis is the word's average difference between its static embedding and contextual embeddings, and the other axis is its bias towards/against contronyms, represented as the difference between the contronym and non-contronym probability for that word. Ideally, we would see a correlation such that as the difference between static and contextual embeddings increases, the bias against the homonym decreases. 
